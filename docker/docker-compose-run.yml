services:
  llama-qnn-run:
    platform: linux/x86_64
    image: chraac/llama-cpp-qnn-builder:latest
    environment:
      EXEC_MOUNT_POINT: /mnt/build_qnn_x86_64
      LD_LIBRARY_PATH: /mnt/build_qnn_x86_64
      RUN_LOG_PATH: /mnt/run_logs
    volumes:
      - ../build_qnn_x86_64:/mnt/build_qnn_x86_64:rx
      - ../run_logs:/mnt/run_logs:w
    command: |
      sh -c "cd $$EXEC_MOUNT_POINT && ./test-backend-ops test -b qnn-npu >> $$RUN_LOG_PATH/test-backend-ops-all-npu.log 2>&1"
    restart: "no"
